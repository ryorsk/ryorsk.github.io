<!DOCTYPE HTML>
<!--
	Prologue by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Ryosuke Araki</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-112919622-1"></script>
		<script>
			window.dataLayer = window.dataLayer || [];
			function gtag(){dataLayer.push(arguments);}
			gtag('js', new Date());

			gtag('config', 'UA-112919622-1');
		</script>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<div id="header">

				<div class="top">

					<!-- Logo -->
						<div id="logo">
							<span class="image avatar48"><img src="images/avatar.jpg" alt="" /></span>
							<h1 id="title">Ryosuke Araki</h1>
							<p>荒木 諒介</p>
						</div>

					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="#top" id="top-link"><span class="icon solid fa-home">Top</span></a></li>
								<li><a href="#bio" id="bio-link"><span class="icon solid fa-user">略歴</span></a></li>
								<li><a href="#research" id="research-link"><span class="icon solid fa-brain">研究内容</span></a></li>
								<li><a href="#pub" id="bub-link"><span class="icon solid fa-newspaper">業績</span></a></li>
								<li><a href="#award" id="award-link"><span class="icon solid fa-award">受賞</span></a></li>
								<li><a href="#ext" id="ext-link"><span class="icon solid fa-chalkboard-teacher">学外活動等</span></a></li>
								<li><a href="#skill" id="skill-link"><span class="icon solid fa-th">所持資格・スキル</span></a></li>

							</ul>
						</nav>

				</div>

				<div class="bottom">

					<!-- Social Icons -->
						<ul class="icons">
							<li><a href="https://ryorsk.wordpress.com/" class="icon brands fa-wordpress"><span class="label">WordPress(Blog)</span></a></li>
							<li><a href="https://twitter.com/ryors_k" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="https://www.facebook.com/AiRfaith" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="https://github.com/ryorsk" class="icon brands fa-github"><span class="label">Github</span></a></li>
							<li><a href="https://www.linkedin.com/in/ryosuke-araki-b79660156/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://www.slideshare.net/RyosukeAraki" class="icon brands fa-slideshare"><span class="label">SlideShare</span></a></li>
							<li><a href="http://www.mprg.cs.chubu.ac.jp/~ryorsk/Research/" class="icon solid fa-warehouse"><span class="label">ResearchPage(members only)</span></a></li>
						</ul>

				</div>

			</div>

		<!-- Main -->
			<div id="main">

				<!-- Top -->
					<section id="top" class="one dark cover">
						<div class="container">

							<header>
								<h2 class="alt">荒木 諒介 (Ryosuke Araki) </h2>
								<p>
									中部大学大学院 工学研究科 博士後期課程 情報工学専攻<br>
									機械知覚&ロボティクスグループ（MPRG: Machine Perception and Robotics Group）<br>
									<a href="http://xpaperchallenge.org/cv/">cvpaper.challenge</a> 研究メンバ<br>
									<a href="https://nagoyacv.connpass.com">名古屋CV・PRML勉強会</a>5代目幹事<br>
									e-mail: ryorsk |at| mprg.cs.chubu.ac.jp
								</p>
							</header>
						</div>
					</section>

				<!-- 略歴 -->
					<section id="bio" class="two">
						<div class="container">

							<header>
								<h2>略歴</h2>
							</header>

							<a href="#" class="image featured"><img src="images/banner3.jpg" alt="" /></a>

							<ul>
								<li>2013年3月 愛知県立岩倉総合高等学校 総合学科 卒業．</li>
								<li>2013年4月 中部大学 工学部 情報工学科 入学．</li>
								<li>2017年3月 中部大学 工学部 情報工学科 次席卒業．学士（工学）．（副専攻 コミュニケーション学 修了）</li>
								<li>2017年4月 中部大学大学院 工学研究科 博士前期課程 情報工学専攻 入学．</li>
								<li>2019年3月 中部大学大学院 工学研究科 博士前期課程 情報工学専攻 修了．修士（工学）．</li>
								<li>2019年4月 中部大学大学院 工学研究科 博士後期課程 情報工学専攻 入学．</li>
							</ul>

						</div>
					</section>


				<!-- 研究内容 -->
					<section id="research" class="three">
						<div class="container">

							<header>
								<h2>研究内容</h2>
							</header>

							<p>
								深層ニューラルネットワーク (DNN) や深層畳み込みニューラルネットワーク (DCNN) などの深層学習はコンピュータビジョン分野において高い認識精度を達成し，
								今日の第3次AIブームを牽引しています．同技術は，ロボティクス分野でも物体の把持位置検出やロボット動作の自動獲得など，普遍的手法として確立されつつあります．
								所属する研究グループ「MPRG」では，深層学習を活用したロボットの制御に必要な画像認識技術の研究や，画像認識結果を与えてロボットを制御する研究に取り組んでいます．
								特に，私は「ロボットでの物体把持位置検出」「把持対象物体の認識」に焦点を当てて研究しています．
							</p>

							<div class="row">
								<div class="col-4 col-12-mobile">
									<article class="item">
										<a href="#" class="image fit"><img src="images/grasping_det.jpg" alt="" /></a>
										<header>
											<h3>Graspabilityを導入したDCNNによる物体把持位置検出</h3>
										</header>
									</article>
									<article class="item">
										<a href="#" class="image fit"><img src="images/objectness-ssd.jpg" alt="" /></a>
										<header>
											<h3>Objectnessを導入したSSDによる未学習物体の検出</h3>
										</header>
									</article>
								</div>
								<div class="col-4 col-12-mobile">
									<article class="item">
										<a href="#" class="image fit"><img src="images/mt-dssd.jpg" alt="" /></a>
										<header>
											<h3>MT-DSSDを用いた物体と物体把持位置の同時検出</h3>
										</header>
									</article>
									<article class="item">
										<a href="#" class="image fit"><img src="images/occlusion_det.jpg" alt="" /></a>
										<header>
											<h3>[共同研究] 多品種ばら積みピッキングにおける物体間の上下関係の予測</h3>
										</header>
									</article>
								</div>
								<div class="col-4 col-12-mobile">
									<article class="item">
										<a href="#" class="image fit"><img src="images/gan-da.jpg" alt="" /></a>
										<header>
											<h3>[共同研究] 脳腫瘍検出に向けたPGGANによるMR画像の水増し</h3>
										</header>
									</article>
								</div>
							</div>

						</div>
					</section>

				<!-- 業績 -->
					<section id="pub" class="four">
						<div class="container">

							<header>
								<h2>業績</h2>
							</header>

							<h3>学位論文</h3>
							<ul>
								<li>2019年2月 修士論文 “<a href="http://mprg.jp/data/FLABResearchArchive/Master/M18/Abstract/araki.pdf">深層学習を用いた物体認識と物体把持位置検出に関する研究</a>”</li>
								<li>2017年2月 卒業論文 “<a href="http://mprg.jp/data/FLABResearchArchive/Bachelor/B16/Abstract/araki.pdf">Graspabilityを導入したDCNNによる物体把持位置検出</a>”</li>
							</ul>

							<h3>Journal / Book chapter</h3>
							<ul>
								<li>[公開予定] C. Han, L. Rundo, <b>R. Araki</b>, Y. Furukawa, G. Mauri, H. Nakayama and H. Hayashi,<br>
									“Combining Noise-to-Image and Image-to-Image GANs: Brain MR Image Augmentation for Tumor Detection”,<br>
									IEEE Access, IEEE. (査読あり, IF: 4.098)</li>
								<li>C. Han, L. Rundo, <b>R. Araki</b>, Y. Furukawa, G. Mauri, H. Nakayama and H. Hayashi,<br>
									“<a href="https://link.springer.com/chapter/10.1007/978-981-13-8950-4_27">Infinite Brain MR Images: PGGAN-based Data Augmentation for Tumor Detection</a>”,<br>
									R. J. Howlett, and L. C. Jain (eds.) Smart Innovation, System and Technologies, vol. 151, pp. 291-303, Springer, 2020. (査読あり，Book chapter)</li>
								<li><b>荒木 諒介</b>, 長谷川 昂宏, 山内 悠嗣, 山下 隆義, 藤吉 弘亘, 堂前 幸康, 川西 亮輔, 関 真規人,<br>
									“<a href="https://ci.nii.ac.jp/naid/130007511508">Graspabilityを導入したDCNNによる物体把持位置検出</a>”,<br>
									日本ロボット学会誌, 36巻, 8号, 2018.（査読あり，論文誌）</li>
							</ul>

							<h3>Presentation (Domestic / International / Workshop etc.)</h3>
							<ul>
								<li>[発表予定] Y. Inagaki, <b>R. Araki</b>, T. Yamashita, H. Fujiyoshi,<br>
									“<a href="#">Detecting Layered Structures of Partially Occluded Objects for Bin Picking</a>”,<br>
									IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2019. (査読あり)</li>
								<li>稲垣 雄介, <b>荒木 諒介</b>, 平川 翼, 山下 隆義, 藤吉 弘亘,<br>
									“<a href="http://mprg.jp/publications/f20190904_inagaki">多品種ばら積みピッキングにおける物体間の上下関係の予測とデータセットの提案</a>”,<br>
									日本ロボット学会学術講演会（RSJ）, 2019.（口頭発表）</li>
								<li><b>荒木 諒介</b>, 大西 剛史, 平川 翼, 山下 隆義, 藤吉 弘亘,<br>
									“<a href="http://mprg.jp/publications/f20190904_araki">Multi-task DSSDによる物体位置と物体把持位置の同時推定</a>”,<br>
									日本ロボット学会学術講演会（RSJ）, 2019.（口頭発表）</li>
								<li>M. Fujita, Y. Domae, R. Kawanishi, G. Garcia, K. Kato, K Shiratsuchi, R. Haraguchi, <b>R. Araki</b>, H. Fujiyoshi, S. Akizuki, M. Hashimoto, A. Causo, A. Noda, H. Okuda, T. Ogasawara, <br>
									“Bin-Picking Robot Using a Multi-Gripper Switching Strategy Based on Object Sparseness”,<br>
									IEEE International Conference on Automation Science and Engineering (CASE), 2019. (査読あり，Regular paper, oral)</li>

								<li>韓 昌熙, 早志 英朗, ルンド レオナルド, <b>荒木 諒介</b>, 永野 雄大, 古川 悠次郎, マウリ ジャンカルロ, 中山 英樹,<br>
									“［ショートペーパー］限られた医用画像で高い精度を出す 〜 脳腫瘍検出に向けた、PGGANによるMR画像の水増し 〜”,<br>
									医用画像研究会（MI）, 2019. （査読あり，口頭発表）</li>

								<li><b>荒木 諒介</b>, 中瀬 架, 福井 宏, 山下 隆義, 藤吉 弘亘,<br>
									“マルチタスク学習を導入したDeconvolutional Single Shot Detectorによる物体検出とセグメンテーションの高精度化”,<br>
									画像の認識・理解シンポジウム（MIRU）, 2018. （査読あり，ポスター発表）</li>

								<li>C. Han, L. Rundo, <b>R. Araki</b>, Y. Furukawa, G. Mauri, H. Nakayama and H. Hayashi,<br>
									“Infinite Brain Tumor Images: Can GAN-based Data Augmentation Improve Tumor Detection on MR Images?”,<br>
									画像の認識・理解シンポジウム（MIRU）, 2018. （査読あり，ポスター発表）</li>

								<li>C. Han, H. Hayashi, L. Rundo, <b>R. Araki</b>, Y. Nagano, Y. Furukawa, G. Mauri and H. Nakayama,<br>
									“Infinite Brain MR Images: PGGAN-based Data Augmentation for Tumor Detection”,<br>
									International Computer Vision Summer School (ICVSS), Sicily, Italy, July 2018.</li>

								<li>C. Han, L. Rundo, <b>R. Araki</b>, Y. Furukawa, G. Mauri, H. Nakayama and H. Hayashi,<br>
									“Infinite Brain MR Images: PGGAN-based Data Augmentation for Tumor Detection”,<br>
									The Italian Workshop on Neural Networks (WIRN), 2018. (査読あり，口頭発表)</li>

								<li><b>R. Araki</b>, T. Yamashita and H. Fujiyoshi,<br>
									“ARC2017 RGB-D Dataset for Object Detection and Segmentation”,<br>
									IEEE International Conference on Robotics and Automation (ICRA), 2018. (Late Breaking Poster Presentation)</li>

								<li><b>荒木 諒介</b>, 韓 昌熙, 早志 英朗, Leonardo Rundo,<br>
									“MIRU2017若手プログラム報告 -GANによる合成脳MR画像生成-”,<br>
									情報処理学会 第212回コンピュータビジョンとイメージメディア研究発表会（CVIM）, 2018.</li>

								<li>C. Han, H. Hayashi, L. Rundo, <b>R. Araki</b>, W. Shimoda, S. Muramatsu, Y. Furukawa, G. Mauri and H. Nakayama,<br>
									“<a href="https://ieeexplore.ieee.org/document/8363678/">GAN-based Synthetic Brain MR Image Generation</a>”,<br>
									IEEE International Symposium on Biomedical Imaging (ISBI), 2018.（査読あり，ポスター発表）</li>

								<li><b>荒木 諒介</b>, 長谷川 昂宏, 山内 悠嗣, 山下 隆義, 藤吉 弘亘, 橋本 学, 堂前 幸康,<br>
									“Objectnessを導入したSSDによる学習データに含まれない未知クラスアイテムの検出”,<br>
									動的画像処理実利用化ワークショップ（DIA）, 2018.（ポスター発表）</li>

								<li><b>荒木 諒介</b>, 長谷川 昂宏, 山内 悠嗣, 山下 隆義, 藤吉 弘亘, 橋本 学, 堂前 幸康,<br>
									“Objectnessを導入したSSDによる学習データに含まれない未知クラスアイテムの検出”,<br>
									情報学ワークショップ（WiNF）, 2017.（口頭発表）</li>

								<li>C. Han, <b>R. Araki</b>, W. Shimoda, S. Muramatsu and H. Hayashi,<br>
									“GAN-based Synthetic Medical Image Generation”,<br>
									画像の認識・理解シンポジウム（MIRU）, 2017.（若手プログラム；口頭，ポスター発表）</li>

								<li><b>荒木 諒介</b>, 長谷川 昂宏, 山内 悠嗣, 山下 隆義, 藤吉 弘亘, 堂前 幸康, 川西 亮輔, 関 真規人,<br>
									“把持のしやすさを考慮した物体把持位置検出の高精度化”,<br>
									情報学ワークショップ（WiNF）, 2016.（ポスター発表）</li>

								<li><b>荒木 諒介</b>, 長谷川 昂宏, 山内 悠嗣, 山下 隆義, 藤吉 弘亘, 堂前 幸康, 川西 亮輔, 関 真規人,<br>
									“<a href="http://mprg.jp/publications/f175">Graspabilityを導入したDCNNによる物体把持位置検出</a>”,<br>
									日本ロボット学会学術講演会（RSJ）, 2016.（口頭発表）</li>

								<li>長谷川 昂宏, Xuanyi Sheing, <b>荒木 諒介</b>, 山内 悠嗣, 山下 隆義, 藤吉 弘亘,<br>
									“<a href="http://mprg.jp/publications/f171">Heterogeneous Learningによるオブジェクトネスと物体把持位置の検出</a>”,<br>
									画像センシングシンポジウム（SSII）, 2016.（ポスター発表）</li>
							</ul>

						</div>
					</section>


				<!-- 受賞 -->
					<section id="award" class="five">
						<div class="container">

							<header>
								<h2>受賞</h2>
							</header>

							<h3>個人/1st author</h3>
							<ul>
								<li>2019年 6月 日本学生支援機構 第一種奨学金 特に優れた業績よる返還免除（一部）</li>
								<li>2019年 1月 中部大学学長表彰 受賞 [<a href="https://www.chubu.ac.jp/event_reports/detail-400.html">Web</a>]</li>
								<li>2018年 1月 中部大学学長表彰 受賞 [<a href="https://www.chubu.ac.jp/event_reports/detail-377.html">Web</a>]</li>
								<li>2017年 1月 中部大学学長表彰 受賞 [<a href="https://www.chubu.ac.jp/event_reports/detail-354.html">Web</a>]</li>
								<li>2016年11月 第14回情報学ワークショップ (WiNF2016) 優秀論文賞 [<a href="http://www.ist.aichi-pu.ac.jp/winf2016/awards.html">Web</a>]</li>
								<li>2016年 1月 NEXT COMMUNICATION AWARD 2015 サービスアイデア部門 準グランプリ [<a href="https://www.nttdocomo.co.jp/campaign_event/tokai/ncf_award/2015.html">Web</a>]</li>
							</ul>

							<h3>団体</h3>
							<ul>
								<li>2019年 6月 Hack U 中部大学 2019 パーソナルコンピューター研究会賞 (Team: PLR) [<a href="https://hacku.yahoo.co.jp/chubu2019/">Web</a>]</li>
								<li>2018年10月 WRS Future Convenience Store Challenge 陳列・廃棄部門 2位，日本ロボット学会特別賞 (Team: ROC2) [<a href="http://worldrobotsummit.org/wrc2018/">Web</a>]</li>
								<li>2017年12月 WRS Future Convenience Store Challenge トライアル大会 陳列・廃棄部門 1位 (Team: ROC2) [<a href="http://sice-si.org/fcsc/the-technology-division/">Web</a>]</li>
								<li>2017年 8月 MIRU2017 若手プログラム 最優秀研究計画賞 (Group: G)[<a href="http://www.am.sanken.osaka-u.ac.jp/MIRU2017wakate/index.html">Web</a>]</li>
								<li>2017年 7月 Amazon Robotics Challenge 2017 Stow Task 3rd Place (Team: MC^2) [<a href="https://www.amazonrobotics.com/#/roboticschallenge/results">Web</a>]</li>
								<li>2017年 2月 第2回HSRユーザ会 優秀成果賞</li>
							</ul>

						</div>
					</section>


				<!-- 学外活動等 -->
					<section id="ext" class="six">
						<div class="container">

							<header>
								<h2>学外活動・対外的活動等</h2>
							</header>

							<ul>
								<li>2019年 9月 <a href="https://nagoyacv.connpass.com/event/143388/">第55回名古屋CV・PRML勉強会</a>で公演「MIRU2019参加報告」</li>
								<li>2019年 8月 2019年度中部大学オックスフォード英語短期研修に参加(8/10 - 9/1)．</li>
								<li>2019年 7月 MIRU2019 若手プログラムに参加．</li>
								<li>2019年 7月 <a href="https://nagoyacv.connpass.com/event/133598/">第54回名古屋CV・PRML勉強会</a>で公演「論文紹介：Triply Supervised Decoder Networks for Joint Detection and Segmentation」
								<li>2019年 4月〜 <a href="https://nagoyacv.connpass.com">名古屋CV・PRML勉強会</a>の5代目幹事に就任．</li>
								<li>2019年 3月 <a href="https://nagoyacv.connpass.com/event/121088/">第53回名古屋CV・PRML勉強会</a>で公演「<a href="https://www.slideshare.net/RyosukeAraki/ss-136687597">楽しい研究のために今からできること 〜新しく研究を始める皆さんへ〜</a>」
								<li>2019年 1月〜 <a href="http://hirokatsukataoka.net/project/cc/index_cvpaperchallenge.html">cvpaper.challenge</a>に参加．</li>
								<li>2018年10月 WRS Future Convenience Store Challenge にチームメンバとして参加．陳列・廃棄部門 2位，日本ロボット学会特別賞受賞．</li>
								<li>2018年 8月 MIRU2018 若手プログラムに参加．</li>
								<li>2018年 6月 <a href="https://nagoyacv.connpass.com/event/87635/">第51回名古屋CV・PRML勉強会</a>で公演「<a href="https://www.slideshare.net/RyosukeAraki/cvpr2018pseudo-mask-augmented-object-detection">CVPR2018論文紹介「Pseudo Mask Augmented Object Detection</a>」
								<li>2018年 5月 <a href="http://hirokatsukataoka.net/project/cc/index_cvpaperchallenge.html">cvpaper.challenge</a>が主宰する<a href="http://hirokatsukataoka.net/project/cc/cvpr2018survey.html">CVPR2018完全読破チャレンジ</a>に参加．</li>
								<li>2018年 4月 <a href="https://nagoyacv.connpass.com/event/82411/">第50回名古屋CV・PRML勉強会</a>で公演「<a href="https://www.slideshare.net/RyosukeAraki/survey-stand-on-the-shoulders-of-giants">Surveyから始まる研究者への道 - Stand on the shoulders of giants -</a>」
								<li>2017年12月 WRS Future Convenience Store Challenge トライアル大会にチームメンバとして参加．陳列・廃棄部門 1位．</li>
								<li>2017年 8月 MIRU2017 若手プログラムに参加．最優秀研究計画賞受賞．</li>
								<li>2017年 7月 Amazon Robotics Challenge 2017にチームメンバとして参加．Stow Task 3rd Place.</li>
								<li>2016年 7月 Amazon Picking Challenge 2016にチームメンバとして参加．</li>
								<li>2016年 1月 NEXT COMMUNICATION AWARD 2015 サービスアイデア部門に作品提出．準グランプリ受賞．</li>
							</ul>

						</div>
					</section>



				<!-- 所持資格・スキル -->
					<section id="skill" class="seven">
						<div class="container">

							<header>
								<h2>所持資格・スキル</h2>
							</header>

							<h3>国家資格</h3>
							<p>（IPA情報処理技術者試験）</p>
							<ul>
								<li>2010年11月 ITパスポート試験（PBT） 合格</li>
								<li>2013年 5月 基本情報技術者試験 合格</li>
								<li>2016年 6月 応用情報技術者試験 合格</li>
							</ul>
							<p>（自動車運転免許）</p>
							<ul>
								<li>2013年 3月 第一種普通自動車免許（現・準中型5t限定） 取得</li>
								<li>2015年 3月 普通自動二輪免許 取得</li>
								<li>2017年 7月 第一種準中型自動車免許（限定解除） 取得</li>
								<li>2018年 3月 大型自動二輪免許 取得</li>
							</ul>
							<p>（その他）</p>
							<ul>
								<li>2014年 1月 第三級アマチュア無線技士 取得</li>
							</ul>

							<h3>語学系</h3>
							<ul>
								<li>2018年12月 TOEIC L&R (IP) 650</li>
							</ul>

							<h3>民間資格・その他</h3>
							<ul>
								<li>2016年 1月 CG-ARTS協会 画像処理エンジニア検定ベーシック 合格</li>
								<li>2016年 1月 CG-ARTS協会 画像処理エンジニア検定エキスパート 合格</li>
								<li>2016年 2月 （一社）音楽電子事業協会 MIDI検定3級 合格</li>
								<li>2016年10月 三菱電機（株） MELFAロボットスクール Fコース 修了</li>
								<li>その他民間資格約10件</li>
							</ul>

						</div>
					</section>


			</div>

		<!-- Footer -->
			<div id="footer">

				<!-- Copyright -->
					<ul class="copyright">
						<li>&copy; Ryosuke Araki. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a>. Modified by ryorsk.</li>
					</ul>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
